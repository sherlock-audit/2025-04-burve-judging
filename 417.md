Shiny Macaroon Raccoon

Medium

# Incorrect Rounding Direction in the `v` Function

# Incorrect Rounding Direction in the `v` Function

### Summary

In the `v` function of `Value.sol`, the use of the `roundUp` parameter is consistently applied in the wrong direction across the system. This leads to an underestimation or overestimation of calculated values, ultimately may break critical system invariants.


### Root Cause

In the `v` function of `Value.sol`:

```solidity
function v( 
    uint256 tX128,
    uint256 eX128,
    uint256 _x,
    bool roundUp
) internal pure returns (uint256 valueX128) {
    uint256 etX128 = FullMath.mulX128(eX128, tX128, roundUp);
    valueX128 = etX128 + 2 * tX128;
    uint256 denomX128 = (_x << 128) + etX128;
    uint256 sqrtNumX128 = etX128 + tX128;
    uint256 subtract;
    if (roundUp) {
        subtract = FullMath.mulDivRoundingUp(
            sqrtNumX128,
            sqrtNumX128,
            denomX128
        );
    } else {
        subtract = FullMath.mulDiv(sqrtNumX128, sqrtNumX128, denomX128);
    }
    if (subtract > valueX128)
        revert XTooSmall(_x, (tX128 / (eX128 + TWOX128)) + 1);
    valueX128 -= subtract;  
}
```

From the above code, we know that the calculation of `v` follows the formula:

```solidity
value = e * t + 2 * t - ((e * t + t)^2 / (x + e * t));
```

It’s important to note that the `roundUp` parameter affects two main parts:

First part:

```solidity
uint256 etX128 = FullMath.mulX128(eX128, tX128, roundUp);
```

Second part:

```solidity
if (roundUp) {
    subtract = FullMath.mulDivRoundingUp(
        sqrtNumX128,
        sqrtNumX128,
        denomX128
    );
} else {
    subtract = FullMath.mulDiv(sqrtNumX128, sqrtNumX128, denomX128);
}
```

Let’s first consider the impact of the first part. For simplicity, assume `roundUp = true`. In this case:

```solidity
uint256 etX128 = FullMath.mulX128(eX128, tX128, roundUp);
```

This value etX128 will be slightly larger.

Mathematically:

$$
V(x) = et + 2t - \frac{(et + t)^2}{x + et}
$$

$$
= \frac{(et + 2t)(x + et) - (et + t)^2}{x + et}
$$

$$
= \frac{etx + e^2t^2 + 2tx + 2et^2 - (e^2t^2 + t^2 + 2et^2)}{x + et}
$$

$$
= \frac{etx + 2tx - t^2}{x + et}
$$

$$
= \frac{(x + et)x + 2tx - t^2 - x^2}{x + et}
$$

$$
= x + \frac{2tx - t^2 - x^2}{x + et}
$$

From the above transformations, we can see that the larger `e * t` is, the smaller `v` becomes. Therefore, when `roundUp = true` and assuming `etX128` has a fractional part (which is highly probable), the computed `etX128` will be slightly larger, making the actual `v` **smaller**.


Next, considering the second part:

```Solidity
if (roundUp) {
    subtract = FullMath.mulDivRoundingUp(
        sqrtNumX128,
        sqrtNumX128,
        denomX128
    );
}
```

This part is simpler — when `roundUp = true` and the division is not exact (again, highly probable), the entire fraction rounds up. Since this part is **subtracted** in the `v` calculation(valueX128 -= subtract), the result for `v` becomes even smaller.

Combining both effects:

When `roundUp = true`, the computed `v` is not rounded up as expected; on the contrary, its value is effectively **rounded down**.


### Attack Path

Example:

Assume:

* `e = 2.1`
* `t = 101`
* `x = 50`

Calculations:

With `roundUp = true`:

* `et = 2.1 × 101 = 203`
* `value = et + 2t = 203 + 202 = 405`

Calculate `subtract`:

* `sqrtNum = et + t = 203 + 101 = 304`
* `denom = x + et = 50 + 203 = 253`
* `subtract = 304^2 / 253 = 366 (rounded up)`
* `value - subtract = 405 - 366 = 39`


With `roundUp = false`:

* `et = 2.1 × 101 = 202`
* `value = et + 2t = 202 + 202 = 404`

Calculate `subtract`:

* `sqrtNum = et + t = 202 + 101 = 303`
* `denom = x + et = 50 + 202 = 252`
* `subtract = 303^2 / 252 = 364 (not rounded up)`
* `value - subtract = 404 - 364 = 40`

The results are exactly the **opposite** of the intended effect.


Practically, almost all places where the `v` function is used for value calculation have this incorrect `roundUp` direction.
The `v` function is the **core** of the entire value calculation system.
In `Value.sol`, the following functions are all influenced by `v`:

```solidity
vDiff()
t()
f()
```

And `Value.sol` itself is the core value calculation module.
For example, in `Closure.sol`, the following functions **all** use the wrong `roundUp` direction:

```solidity
addValueSingle()
removeValueSingle()
addTokenForValue()
removeTokenForValue()
swapInExact()
simSwapInExact()
swapOutExact()
simSwapOutExact()
iterSingleValueDiff()
```

A particularly important point is in the `f` function, which calculates the difference between the sum of the token values and `n * target`.

```solidity
function f(
    uint256 tX128,
    uint256[] memory esX128,
    uint256[] memory xs
) internal pure returns (int256 ftX128) {
    uint256 n = xs.length;
    for (uint256 i = 0; i < n; ++i) {
        ftX128 += int256(v(tX128, esX128[i], xs[i], false)); 
    }
    ftX128 -= int256(n * tX128);
}
```

Here, `roundUp = false`. The intention is to **underestimate** the value of each token.


The entire system is designed to maintain the following invariant:

> The "value" of the closure (according to the formulas) can never be more than deMinimus * (number of tokens in the closure) from the target value of the pool times number of tokens in the closure.

In the actual system, the iterative target calculation function handles the right-hand side more leniently.
If the value slightly exceeds the right endpoint but remains within `searchParams.targetSlippageX128`, it is still considered acceptable, because slightly exceeding the value is less harmful than underestimating.

```Solidity
ftX128 = f(tX128, esX128, xs);            
if (-deMinX128 <= ftX128 && ftX128 <= deMinX128) {
    done = true;
    break;
}

...

if (
    -deMinX128 <= ftX128 &&
    ftX128 <= searchParams.targetSlippageX128 
) {
    done = true;
    break;
}
```

Thus, using `roundUp = false` here is reasonable.

However, in practice, the `false` value here **actually causes rounding up**.


```solidity
self.deMinimusX128 = 100;
self.targetSlippageX128 = 1e12;
```

By default:(−deMinX128 = −n * self.deMinimusX128 = −100n﻿)

Given that indivisible cases happen with high probability during calculation, the actual deviation can be estimated as \( $1 \times n = n $\).That is to say, the final result will be larger than the expected rounded-down result by n.

Focusing only on the case where $ftX128 < 0$, when $-101n \leq ftX128 < -100n$, the invariant should normally not be considered satisfied. However, due to the logic that effectively adds $+n$ to the final result, the system mistakenly treats this as satisfying the invariant and accepts this $target$ as the new target. This directly breaks the intended invariant guarantees and undermines the system’s integrity.

Additionally, the distribution of \( $ftX128$ \) within \( $-deMinX128 \leq ftX128 \leq searchParams.targetSlippageX128 $\) is **not uniformly random**, which involves complex mathematical reasoning.
Here we only qualitatively analyze the potential invariant-breaking situation.
Notably, when the administrator configures `deMinX128` to be smaller, demanding stricter error control, the potential harm becomes even greater.


### Affected Code

https://github.com/sherlock-audit/2025-04-burve/blob/main/Burve/src/multi/Value.sol#L79-L102


### Impact

This issue can break system invariants, cause incorrect new targets to be set when the invariant fails, and under stricter error tolerance settings (small `deMinX128`), the system becomes even more vulnerable. Moreover, the misused rounding logic systematically under- or overestimates values, cascading into all dependent functions and leading to systemic miscalculations.


### Mitigation

Correct the rounding logic to match the intended estimation direction (underestimate or overestimate).Document the rounding design clearly, especially where system invariants depend on it.