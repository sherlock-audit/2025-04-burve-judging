Alert Tiger Fish

Medium

# Precision loss in fixed-point arithmetic causes token dust accumulation during compounding

### Summary

Imprecise fixed-point arithmetic in the Burve protocol's compounding mechanism will cause gradual token dust accumulation for all users as small amounts of tokens remain unused during compounding operations, reducing overall protocol efficiency.

### Root Cause

In [Burve.sol:890](https://github.com/sherlock-audit/2025-04-burve/blob/main/Burve/src/single/Burve.sol#L890) the contract calculates nominal liquidity during compounding using fixed-point division:

```solidity
uint256 nominalLiq0 = amount0InUnitLiqX64 > 0
    ? (collected0 << 64) / amount0InUnitLiqX64
    : uint256(type(uint128).max);
uint256 nominalLiq1 = amount1InUnitLiqX64 > 0
    ? (collected1 << 64) / amount1InUnitLiqX64
    : uint256(type(uint128).max);
```

This implementation causes precision loss due to division operations and remainder handling, where small amounts of tokens cannot be converted into liquidity and remain unused.

### Internal Pre-conditions

1. The contract needs to have accumulated fee tokens from trading.
2. The compoundV3Ranges() function needs to be called (which happens automatically during mint/burn operations).
3. The amount of accumulated tokens needs to not be perfectly divisible by the required token amounts for a unit of liquidity.

### External Pre-conditions

None specific required.

### Attack Path

This isn't an attack but rather an inefficiency in the protocol:
1. Users trade on Uniswap pools managed by the Burve contract
2. Trading fees accumulate in the contract
3. When compoundV3Ranges() is called during mint/burn operations, it calculates liquidity to mint from accumulated fees
4. Due to precision loss, some tokens remain in the contract as "dust"
5. Over time and with many operations, these dust amounts accumulate and don't get reinvested

### Impact

All users of the protocol suffer a gradual loss of efficiency as token dust amounts accumulate in the contract instead of being compounded. While individual instances are minimal (often less than 1 wei per token), the cumulative impact across all positions and over time could be material.

### PoC

The test that confirmed this issue:
```solidity
function test_ArithmeticPrecisionLoss() public forkOnly {
    // Setup - mint to alice first to establish some tokens
    deal(address(token0), alice, type(uint256).max);
    deal(address(token1), alice, type(uint256).max);
    vm.startPrank(alice);
    token0.approve(address(burve), type(uint256).max);
    token1.approve(address(burve), type(uint256).max);
    burve.mint(alice, 10000, 0, type(uint128).max);
    vm.stopPrank();
    
    // Create a very imbalanced set of fees to trigger precision loss
    uint256 smallAmount = 100;
    uint256 largeAmount = 10**18 + 1; // Will cause division with remainder
    
    // Deal these amounts to the contract (simulating fees)
    deal(address(token0), address(burve), smallAmount);
    deal(address(token1), address(burve), largeAmount);
    
    // Record pre-compound state
    uint256 preCompoundBalance0 = token0.balanceOf(address(burve));
    uint256 preCompoundBalance1 = token1.balanceOf(address(burve));
    uint128 preCompoundLiquidity = burve.totalNominalLiq();
    
    // Trigger compounding
    burve.compoundV3RangesExposed();
    
    // Check post-compound state
    uint256 postCompoundBalance0 = token0.balanceOf(address(burve));
    uint256 postCompoundBalance1 = token1.balanceOf(address(burve));
    
    // Verify that some tokens remain unused due to precision loss
    assertTrue(
        postCompoundBalance0 > 0 || postCompoundBalance1 > 0,
        "Some tokens should remain unused due to precision limitations"
    );
}
```

This test has passed, confirming the precision loss issue.

### Mitigation

To mitigate this issue:

1. Consider implementing a more sophisticated rounding mechanism that minimizes leftover dust.
2. Implement a periodic "dust sweep" function that can combine accumulated dust tokens into liquidity once they reach a threshold.
3. Use a dedicated fixed-point arithmetic library with better precision handling.
4. Alternatively, maintain an accounting of "owed" amounts to users that couldn't be compounded, and include these in future compounding operations.